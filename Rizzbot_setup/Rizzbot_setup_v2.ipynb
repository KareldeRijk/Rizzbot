{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2459a273",
   "metadata": {},
   "source": [
    "This notebook sets up the Agentic system.\n",
    "The simplified flow of the system is as follows:\n",
    "User gives input question as a prompt -> Preprocess the question via prompt tuning -> do a semantic search query over the summary database  -> \n",
    "\n",
    "(branch 1): is the answer in a summary (or spread over multiple)? -> use the summary/summaries to generate summary answer -> output answer to user\n",
    "\n",
    "(branch 2): is the answer not in a summary? -> semantic search query the entire dataset for the answer -> retrieve the relevant chunks -> generate summary of the relevant results -> output answer to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fddd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code implements the RAG system for the Agentic chatbot, called Rizzbot.\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pydantic import SecretStr\n",
    "from functools import lru_cache\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "# LangSmith imports\n",
    "from langsmith import Client\n",
    "import langsmith\n",
    "\n",
    "# Pinecone\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "# Initialize LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"rizzbot\"\n",
    "\n",
    "# Set up API keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"Container for search results\"\"\"\n",
    "    content: str\n",
    "    score: float\n",
    "    source: str\n",
    "    metadata: Dict = None\n",
    "\n",
    "class Rizzbot:\n",
    "    \"\"\"\n",
    "    Agentic chatbot system for charisma and personal development questions.\n",
    "    Uses RAG with Pinecone vector stores and AWS S3 for summaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the RAG system with all required components\"\"\"\n",
    "        self.similarity_threshold = 0.85\n",
    "        self.top_k = 3\n",
    "        \n",
    "        # Topic ID constraints for rizzbot-summaries index\n",
    "        self.min_topic_id = 0\n",
    "        self.max_topic_id = 53\n",
    "        \n",
    "        # Initialize summary cache\n",
    "        self.summary_cache = {}\n",
    "        self.cache_max_size = 100  # Maximum number of summaries to cache\n",
    "        self.cache_ttl = 3600  # Cache TTL in seconds (1 hour)\n",
    "        \n",
    "        # Initialize LangSmith client\n",
    "        self.langsmith_client = Client(api_key=langsmith_api_key)\n",
    "        \n",
    "        # Initialize OpenAI components\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.25,\n",
    "            api_key=openai_api_key,\n",
    "            tags=[\"rizzbot_v1\"]\n",
    "        )\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # Initialize Pinecone\n",
    "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
    "        \n",
    "        # Initialize vector stores\n",
    "        self._init_vector_stores()\n",
    "        \n",
    "        # Initialize AWS S3 client\n",
    "        self.s3_client = boto3.client(\"s3\")\n",
    "        \n",
    "        # Initialize prompts\n",
    "        self._init_prompts()\n",
    "    \n",
    "    def _init_vector_stores(self):\n",
    "        \"\"\"Initialize Pinecone vector stores\"\"\"\n",
    "        # Main dataset index - using full_text field\n",
    "        self.main_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot\",\n",
    "            embedding=self.embeddings,\n",
    "            text_key=\"full_text\"  # Specify the correct text field\n",
    "        )\n",
    "        \n",
    "        # Clusters index\n",
    "        self.clusters_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot-clusters\", \n",
    "            embedding=self.embeddings\n",
    "        )\n",
    "        \n",
    "        # Summaries index - topic_id metadata field contains integers 0-53\n",
    "        self.summaries_index = self.pc.Index(\"rizzbot-summaries\")\n",
    "    \n",
    "    def _init_prompts(self):\n",
    "        \"\"\"Initialize prompt templates\"\"\"\n",
    "        self.summary_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a charisma and personal development expert. Based on the following summary/summaries, \n",
    "        provide a comprehensive and helpful answer to the user's question.\n",
    "        \n",
    "        User Question: {question}\n",
    "        \n",
    "        Relevant Summary/Summaries:\n",
    "        {summaries}\n",
    "        \n",
    "        Instructions:\n",
    "        - Provide a clear, actionable answer based on the summaries\n",
    "        - Be conversational and engaging\n",
    "        - If the summaries don't fully address the question, mention this limitation\n",
    "        - Keep your response focused and practical\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        \n",
    "        self.full_search_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a charisma and personal development expert. Based on the following relevant content \n",
    "        from the database, provide a comprehensive and helpful answer to the user's question.\n",
    "        \n",
    "        User Question: {question}\n",
    "        \n",
    "        Relevant Content:\n",
    "        {content}\n",
    "        \n",
    "        Instructions:\n",
    "        - Synthesize the information to provide a clear, actionable answer\n",
    "        - Be conversational and engaging\n",
    "        - Focus on practical advice and insights\n",
    "        - If the content doesn't fully address the question, mention this limitation\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        \n",
    "        self.no_answer_response = \"\"\"My apologies, but I don't have a good answer for you based on the information in my database. My database is limited up to the past 5 years. For further research, we recommend you visit the source of my knowledge: https://www.youtube.com/user/Charismaoncommand/\"\"\"\n",
    "    \n",
    "    def _is_cache_valid(self, timestamp: float) -> bool:\n",
    "        \"\"\"Check if cache entry is still valid based on TTL\"\"\"\n",
    "        return time.time() - timestamp < self.cache_ttl\n",
    "    \n",
    "    def _clean_cache(self):\n",
    "        \"\"\"Remove expired entries and maintain cache size limit\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove expired entries\n",
    "        expired_keys = [\n",
    "            key for key, (_, timestamp) in self.summary_cache.items()\n",
    "            if not self._is_cache_valid(timestamp)\n",
    "        ]\n",
    "        for key in expired_keys:\n",
    "            del self.summary_cache[key]\n",
    "        \n",
    "        # If cache is still too large, remove oldest entries\n",
    "        if len(self.summary_cache) > self.cache_max_size:\n",
    "            # Sort by timestamp and remove oldest\n",
    "            sorted_items = sorted(\n",
    "                self.summary_cache.items(), \n",
    "                key=lambda x: x[1][1]  # Sort by timestamp\n",
    "            )\n",
    "            items_to_remove = len(self.summary_cache) - self.cache_max_size\n",
    "            for key, _ in sorted_items[:items_to_remove]:\n",
    "                del self.summary_cache[key]\n",
    "    \n",
    "    def _get_cached_summary(self, topic_id: int) -> Optional[str]:\n",
    "        \"\"\"Get summary from cache if available and valid\"\"\"\n",
    "        cache_key = f\"topic_{topic_id}\"\n",
    "        if cache_key in self.summary_cache:\n",
    "            summary, timestamp = self.summary_cache[cache_key]\n",
    "            if self._is_cache_valid(timestamp):\n",
    "                return summary\n",
    "            else:\n",
    "                # Remove expired entry\n",
    "                del self.summary_cache[cache_key]\n",
    "        return None\n",
    "    \n",
    "    def _cache_summary(self, topic_id: int, summary: str):\n",
    "        \"\"\"Add summary to cache\"\"\"\n",
    "        self._clean_cache()  # Clean cache before adding new entry\n",
    "        cache_key = f\"topic_{topic_id}\"\n",
    "        self.summary_cache[cache_key] = (summary, time.time())\n",
    "    \n",
    "    def _fetch_single_summary_from_s3(self, topic_id: int) -> Optional[str]:\n",
    "        \"\"\"Fetch a single summary from S3\"\"\"\n",
    "        bucket_name = \"rizzbot-temp-storage\"\n",
    "        base_path = \"rizzbot/Summaries/summaries_1kwords/\"\n",
    "        \n",
    "        try:\n",
    "            key = f\"{base_path}topic_{topic_id}.json\"\n",
    "            response = self.s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "            content = response['Body'].read().decode('utf-8')\n",
    "            # Handle both JSON and plain text formats\n",
    "            summary_text = json.loads(content) if content.startswith('{') else content\n",
    "            return str(summary_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not retrieve topic_{topic_id}.json: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _is_valid_topic_id(self, topic_id: int) -> bool:\n",
    "        \"\"\"Validate that topic_id is within expected range (0-53)\"\"\"\n",
    "        return self.min_topic_id <= topic_id <= self.max_topic_id\n",
    "\n",
    "    def search_summaries(self, question: str, topic_id_filter: Optional[int] = None) -> List[int]:\n",
    "        \"\"\"\n",
    "        Search the rizzbot-summaries index manually using the Pinecone SDK, bypassing LangChain's text assumptions.\n",
    "        Returns: List of relevant topic IDs\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create embedding for the question\n",
    "            embedded_query = self.embeddings.embed_query(question)\n",
    "            \n",
    "            # Prepare filter (if any)\n",
    "            filter_dict = {}\n",
    "            if topic_id_filter is not None:\n",
    "                if self._is_valid_topic_id(topic_id_filter):\n",
    "                    filter_dict[\"topic_id\"] = {\"$eq\": topic_id_filter}\n",
    "                else:\n",
    "                    print(f\"Warning: topic_id {topic_id_filter} is outside valid range\")\n",
    "                    return []\n",
    "\n",
    "            # Access the index directly\n",
    "            index = self.summaries_index\n",
    "\n",
    "            query_response = index.query(\n",
    "                vector=embedded_query,\n",
    "                top_k=self.top_k,\n",
    "                include_metadata=True,\n",
    "                filter=filter_dict or None\n",
    "            )\n",
    "\n",
    "            topic_ids = []\n",
    "            for match in query_response.get(\"matches\", []):\n",
    "                score = match.get(\"score\", 0.0)\n",
    "                if score >= self.similarity_threshold:\n",
    "                    metadata = match.get(\"metadata\", {})\n",
    "                    raw_id = metadata.get(\"topic_id\")\n",
    "                    try:\n",
    "                        topic_id = int(raw_id)\n",
    "                        if self._is_valid_topic_id(topic_id):\n",
    "                            topic_ids.append(topic_id)\n",
    "                        else:\n",
    "                            print(f\"Topic ID {topic_id} out of range\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not parse topic_id: {raw_id} — {e}\")\n",
    "            return topic_ids\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying Pinecone summaries: {e}\")\n",
    "            return []\n",
    "\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def search_full_dataset(self, question: str) -> List[SearchResult]:\n",
    "        \"\"\"Search in the full dataset index\"\"\"\n",
    "        try:\n",
    "            results = self.main_vectorstore.similarity_search_with_score(\n",
    "                question, \n",
    "                k=self.top_k\n",
    "            )\n",
    "            \n",
    "            search_results = []\n",
    "            for doc, score in results:\n",
    "                search_results.append(SearchResult(\n",
    "                    content=doc.page_content,\n",
    "                    score=score,\n",
    "                    source=\"full_dataset\",\n",
    "                    metadata=doc.metadata\n",
    "                ))\n",
    "            \n",
    "            return search_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching full dataset: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def get_s3_summaries(self, topic_ids: List[int]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve summaries with caching and batching optimizations\n",
    "        \n",
    "        Args:\n",
    "            topic_ids: List of topic IDs to retrieve (should be 0-53)\n",
    "            \n",
    "        Returns:\n",
    "            List of summary texts\n",
    "        \"\"\"\n",
    "        # Filter valid topic IDs\n",
    "        valid_topic_ids = [tid for tid in topic_ids if self._is_valid_topic_id(tid)]\n",
    "        invalid_topic_ids = [tid for tid in topic_ids if not self._is_valid_topic_id(tid)]\n",
    "        \n",
    "        if invalid_topic_ids:\n",
    "            print(f\"Warning: Skipping invalid topic_ids: {invalid_topic_ids} (valid range: {self.min_topic_id}-{self.max_topic_id})\")\n",
    "        \n",
    "        if not valid_topic_ids:\n",
    "            print(\"No valid topic_ids to retrieve\")\n",
    "            return []\n",
    "        \n",
    "        summaries = []\n",
    "        uncached_ids = []\n",
    "        \n",
    "        # Step 1: Check cache for existing summaries\n",
    "        for topic_id in valid_topic_ids:\n",
    "            cached_summary = self._get_cached_summary(topic_id)\n",
    "            if cached_summary:\n",
    "                summaries.append(cached_summary)\n",
    "                print(f\"Retrieved topic_{topic_id} from cache\")\n",
    "            else:\n",
    "                uncached_ids.append(topic_id)\n",
    "        \n",
    "        # Step 2: Batch fetch uncached summaries from S3\n",
    "        if uncached_ids:\n",
    "            print(f\"Fetching {len(uncached_ids)} summaries from S3...\")\n",
    "            \n",
    "            # Use ThreadPoolExecutor for concurrent S3 requests\n",
    "            with ThreadPoolExecutor(max_workers=min(len(uncached_ids), 5)) as executor:\n",
    "                # Submit all fetch tasks\n",
    "                future_to_topic = {\n",
    "                    executor.submit(self._fetch_single_summary_from_s3, topic_id): topic_id\n",
    "                    for topic_id in uncached_ids\n",
    "                }\n",
    "                \n",
    "                # Collect results as they complete\n",
    "                for future in as_completed(future_to_topic):\n",
    "                    topic_id = future_to_topic[future]\n",
    "                    try:\n",
    "                        summary = future.result()\n",
    "                        if summary:\n",
    "                            summaries.append(summary)\n",
    "                            # Cache the retrieved summary\n",
    "                            self._cache_summary(topic_id, summary)\n",
    "                            print(f\"Retrieved and cached topic_{topic_id}\")\n",
    "                        else:\n",
    "                            print(f\"Failed to retrieve topic_{topic_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching topic_{topic_id}: {e}\")\n",
    "        \n",
    "        print(f\"Total summaries retrieved: {len(summaries)}\")\n",
    "        return summaries\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def generate_summary_answer(self, question: str, summaries: List[str]) -> str:\n",
    "        \"\"\"Generate answer based on summaries\"\"\"\n",
    "        combined_summaries = \"\\n\\n\".join(summaries)\n",
    "        \n",
    "        chain = self.summary_answer_prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"summaries\": combined_summaries\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def generate_full_search_answer(self, question: str, search_results: List[SearchResult]) -> str:\n",
    "        \"\"\"Generate answer based on full dataset search results\"\"\"\n",
    "        combined_content = \"\\n\\n\".join([result.content for result in search_results])\n",
    "        \n",
    "        chain = self.full_search_answer_prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"content\": combined_content\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def answer_question(self, question: str, topic_id_filter: Optional[int] = None) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Main method to answer user questions following the RAG flow\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            topic_id_filter: Optional specific topic_id to search within (0-53)\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing answer, source, and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Step 1: Search summaries\n",
    "            print(\"Searching summaries...\")\n",
    "            topic_ids = self.search_summaries(question, topic_id_filter)\n",
    "            if topic_ids:\n",
    "                print(f\"Found relevant topic IDs: {topic_ids}\")\n",
    "                full_summaries = self.get_s3_summaries(topic_ids)\n",
    "                if full_summaries:\n",
    "                    answer = self.generate_summary_answer(question, full_summaries)\n",
    "                    return {\n",
    "                        \"answer\": answer,\n",
    "                        \"source\": \"summaries\",\n",
    "                        \"num_sources\": len(full_summaries),\n",
    "                        \"confidence_scores\": [],  # You could optionally store Pinecone scores earlier\n",
    "                        \"topic_ids\": topic_ids\n",
    "                    }                \n",
    "                print(f\"Extracted valid topic IDs: {topic_ids}\")\n",
    "                \n",
    "                # Get full summaries from S3\n",
    "                if topic_ids:\n",
    "                    full_summaries = self.get_s3_summaries(topic_ids)\n",
    "                    if full_summaries:\n",
    "                        answer = self.generate_summary_answer(question, full_summaries)\n",
    "                        return {\n",
    "                            \"answer\": answer,\n",
    "                            \"source\": \"summaries\",\n",
    "                            \"num_sources\": len(full_summaries),\n",
    "                            \"confidence_scores\": [r.score for r in summary_results],\n",
    "                            \"topic_ids\": topic_ids\n",
    "                        }\n",
    "                    else:\n",
    "                        print(\"No summaries retrieved from S3, falling back to full dataset search\")\n",
    "                else:\n",
    "                    print(\"No valid topic IDs found in metadata, falling back to full dataset search\")\n",
    "            \n",
    "            # Step 2: Search full dataset (only if not filtering by topic_id)\n",
    "            if topic_id_filter is None:\n",
    "                print(\"Searching full dataset...\")\n",
    "                full_results = self.search_full_dataset(question)\n",
    "                \n",
    "                if full_results:\n",
    "                    print(f\"Found {len(full_results)} relevant chunks\")\n",
    "                    answer = self.generate_full_search_answer(question, full_results)\n",
    "                    return {\n",
    "                        \"answer\": answer,\n",
    "                        \"source\": \"full_dataset\", \n",
    "                        \"num_sources\": len(full_results),\n",
    "                        \"confidence_scores\": [r.score for r in full_results]\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"Topic filter ({topic_id_filter}) specified, skipping full dataset search\")\n",
    "            \n",
    "            # Step 3: No relevant results found\n",
    "            print(\"No relevant results found\")\n",
    "            return {\n",
    "                \"answer\": self.no_answer_response,\n",
    "                \"source\": \"none\",\n",
    "                \"num_sources\": 0,\n",
    "                \"confidence_scores\": []\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in answer_question: {e}\")\n",
    "            return {\n",
    "                \"answer\": self.no_answer_response,\n",
    "                \"source\": \"error\",\n",
    "                \"num_sources\": 0,\n",
    "                \"confidence_scores\": [],\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "# Convenience function for easy usage\n",
    "def create_rizzbot():\n",
    "    \"\"\"Factory function to create and return a Rizzbot instance\"\"\"\n",
    "    return Rizzbot()\n",
    "\n",
    "# Example usage function\n",
    "@langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "def ask_charisma_question(bot: Rizzbot, question: str, topic_id_filter: Optional[int] = None, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Ask a question to the charisma bot and get a formatted response\n",
    "    \n",
    "    Args:\n",
    "        bot: Rizzbot instance\n",
    "        question: User's question\n",
    "        topic_id_filter: Optional specific topic_id to search within (0-53)\n",
    "        verbose: Whether to print detailed information\n",
    "    \n",
    "    Returns:\n",
    "        Dict with answer and metadata\n",
    "    \"\"\"\n",
    "    result = bot.answer_question(question, topic_id_filter)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        if topic_id_filter is not None:\n",
    "            print(f\"Topic Filter: {topic_id_filter}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(f\"\\n Metadata:\")\n",
    "        print(f\"  Source: {result['source']}\")\n",
    "        print(f\"  Number of sources: {result['num_sources']}\")\n",
    "        if result['confidence_scores']:\n",
    "            print(f\"  Confidence scores: {[f'{score:.3f}' for score in result['confidence_scores']]}\")\n",
    "        if 'topic_ids' in result:\n",
    "            print(f\"  Topic IDs used: {result['topic_ids']}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380be110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Rizzbot System...\n",
      "System ready!\n",
      "Searching summaries...\n",
      "Searching full dataset...\n",
      "Found 3 relevant chunks\n",
      "\n",
      "==================================================\n",
      "Question: What is the ROLLS system and how can it help me improve my charisma?\n",
      "==================================================\n",
      "Answer: The ROLLS system isn't directly mentioned in the content provided, so I can't give you a detailed explanation of what it specifically entails. However, I can offer some general advice on improving charisma based on the themes and insights from the content.\n",
      "\n",
      "Charisma is often about building rapport, confidence, and effective communication. Here are some practical steps you can take to enhance your charisma:\n",
      "\n",
      "1. **Build Rapport**: Establishing a connection with others is crucial. This involves active listening, showing genuine interest in others, and finding common ground. The content mentions the importance of rapport in negotiations and relationships, which is a key component of charisma.\n",
      "\n",
      "2. **Confidence**: Confidence can significantly boost your charisma. The Charisma University course mentioned in the content emphasizes building confidence through structured daily actions. Confidence helps you engage more effectively with others and present yourself with assurance.\n",
      "\n",
      "3. **Effective Communication**: Being clear and articulate in your communication is vital. This includes not only what you say but also how you say it—your tone, body language, and eye contact all play a role.\n",
      "\n",
      "4. **Personal Development**: Engaging in activities that promote self-awareness and growth, such as reading diverse perspectives or practicing self-reflection, can enhance your charisma by making you more relatable and insightful.\n",
      "\n",
      "5. **Handling Disagreements Gracefully**: The content highlights the importance of maintaining relationships even when disagreements occur. Being able to negotiate and handle conflicts without being manipulative or vindictive can strengthen your charisma.\n",
      "\n",
      "While the ROLLS system isn't detailed here, these general principles can help you on your journey to becoming more charismatic. If you're interested in a structured approach, exploring courses like Charisma University might be beneficial. Remember, charisma is a skill that can be developed with practice and dedication.\n",
      "\n",
      " Metadata:\n",
      "  Source: full_dataset\n",
      "  Number of sources: 3\n",
      "  Confidence scores: ['0.068', '0.057', '0.056']\n",
      "==================================================\n",
      "\n",
      "Searching summaries...\n",
      "Searching full dataset...\n",
      "Found 3 relevant chunks\n",
      "\n",
      "==================================================\n",
      "Question: Can you give me concrete tips on how to be a better public speaker?\n",
      "==================================================\n",
      "Answer: Becoming a better public speaker is a fantastic goal, and there are several concrete steps you can take to improve your skills. Here are some practical tips to help you on your journey:\n",
      "\n",
      "1. **Build Confidence Through Practice**: Confidence is key in public speaking. One way to build it is through consistent practice. Consider joining a program like Charisma University, which offers a structured approach to enhancing your charisma and confidence. As shared by a member, the program helped her transform from a nervous speaker to someone who could command the stage in front of 2,000 business owners.\n",
      "\n",
      "2. **Engage Your Audience**: To be an effective speaker, it's crucial to connect with your audience. This involves making eye contact, using gestures, and varying your vocal tone to keep the audience engaged. Remember, your goal is to create a rapport with your listeners, making them feel involved in your presentation.\n",
      "\n",
      "3. **Prepare and Structure Your Content**: Organize your speech with a clear beginning, middle, and end. Start with a strong opening to grab attention, present your main points clearly, and conclude with a memorable closing. This structure helps in maintaining a logical flow and keeps your audience engaged.\n",
      "\n",
      "4. **Handle Nervousness**: It's normal to feel nervous before speaking. Techniques such as deep breathing, visualization, and positive affirmations can help calm your nerves. Remember, even experienced speakers feel nervous; the key is to channel that energy positively.\n",
      "\n",
      "5. **Seek Feedback and Reflect**: After each speaking engagement, seek feedback from trusted peers or mentors. Reflect on what went well and what could be improved. This continuous feedback loop is essential for growth and improvement.\n",
      "\n",
      "6. **Learn from Others**: Watch and analyze speeches from accomplished speakers. Pay attention to their delivery style, how they engage the audience, and how they handle questions. Learning from others can provide valuable insights and inspiration.\n",
      "\n",
      "While the content from Charisma University highlights the benefits of their program in building confidence and charisma, these tips provide a broader approach to enhancing your public speaking skills. If you're interested in a more structured program, exploring such courses might be beneficial. Remember, becoming a great public speaker is a journey, and with dedication and practice, you'll continue to improve. Good luck!\n",
      "\n",
      " Metadata:\n",
      "  Source: full_dataset\n",
      "  Number of sources: 3\n",
      "  Confidence scores: ['0.053', '0.044', '0.042']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo cell \n",
    "# Demo: How to use the Rizzbot System\n",
    "# Run this in a Jupyter notebook cell after the main system code\n",
    "\n",
    "# Initialize the bot (this will take a moment as it connects to all services)\n",
    "print(\"Initializing Rizzbot System...\")\n",
    "bot = create_rizzbot()\n",
    "print(\"System ready!\")\n",
    "\n",
    "# Test questions\n",
    "test_questions = [ \n",
    "    \"What is the ROLLS system and how can it help me improve my charisma?\",\n",
    "    \"Can you give me concrete tips on how to be a better public speaker?\",\n",
    "]\n",
    "\n",
    "# Test the system with different questions\n",
    "for question in test_questions:\n",
    "    result = ask_charisma_question(bot, question, verbose=True)\n",
    "    \n",
    "    # You can also access individual components:\n",
    "    # print(f\"Just the answer: {result['answer']}\")\n",
    "    # print(f\"Source type: {result['source']}\")\n",
    "\n",
    "# You can also use the bot directly for more control:\n",
    "# custom_result = bot.answer_question(\"Your custom question here\")\n",
    "# print(custom_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
