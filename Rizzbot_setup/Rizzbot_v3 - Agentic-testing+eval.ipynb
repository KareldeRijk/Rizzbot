{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2459a273",
   "metadata": {},
   "source": [
    "This notebook sets up the Agentic system.\n",
    "The simplified flow of the system is as follows:\n",
    "User gives input question as a prompt -> Preprocess the question via prompt tuning -> do a semantic search query over the summary database  -> \n",
    "\n",
    "(branch 1): is the answer in a summary (or spread over multiple)? -> use the summary/summaries to generate summary answer -> output answer to user\n",
    "\n",
    "(branch 2): is the answer not in a summary? -> semantic search query the entire dataset for the answer -> retrieve the relevant chunks -> generate summary of the relevant results -> output answer to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fddd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Starting test run for Rizzbot...\n",
      "\n",
      "[INIT] Starting Rizzbot initialization...\n",
      "[ENV] Loading environment variables from .env file...\n",
      "[ENV] Environment variables set.\n",
      "[LLM] Main LLM (gpt-4o) initialized.\n",
      "[LLM] Expansion LLM (gpt-3.5-turbo) initialized.\n",
      "[Embeddings] OpenAI embeddings initialized.\n",
      "[Pinecone] Pinecone client initialized.\n",
      "[VectorStore] Summaries vector store initialized.\n",
      "[VectorStore] Full vector store initialized.\n",
      "[Chain] Building agent chain...\n",
      "[Chain] Agent chain constructed.\n",
      "[INIT] Rizzbot initialized and ready.\n",
      "\n",
      "[Test] Asking: What is the capital of France?\n",
      "\n",
      "[Test] Question: What is the capital of France?\n",
      "[Answer] Received question: What is the capital of France?\n",
      "[Search:Hybrid] Embedding question...\n",
      "[Embed] Embedding question: What is the capital of France?\n",
      "[Embed] Embedding result length: 1536\n",
      "[Search:Hybrid] Trying summaries vectorstore...\n",
      "[Similarity] Score: 0.1051 | Text: Topic ID: 16\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.0755 | Text: Topic ID: 33\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.0166 | Text: Topic ID: 44\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.0498 | Text: Topic ID: 39\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.0500 | Text: Topic ID: 27\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Search:Hybrid] 0 docs passed threshold in summaries.\n",
      "[Search:Hybrid] Trying full vectorstore...\n",
      "[Similarity] Score: 0.0421 | Text:  Charity Water through the link in the description. It's a birthday campaign and...\n",
      "[Similarity] Score: 0.0149 | Text:  out, you can do so in the link below. It comes with a 60-day money-back guarant...\n",
      "[Similarity] Score: 0.0167 | Text:  Either way, I hope you enjoyed this video and I look forward to seeing you in t...\n",
      "[Similarity] Score: 0.0398 | Text:  in the next one....\n",
      "[Similarity] Score: 0.0172 | Text:  is getting a redesign so I'm very, very proud to share it with you today. So I ...\n",
      "[Similarity] Score: -0.0043 | Text: 've had thousands of members go through this course, get a ton out of it — intro...\n",
      "[Search:Hybrid] 0 docs passed threshold in full.\n",
      "[Answer] Insufficient documents found (0 docs, need 2). Returning fallback response.\n",
      "[Test] Answer: Sorry bro, I couldn't find enough info to answer that confidently.\n",
      "\n",
      "[Test] All questions answered. Check test_answers.txt for results.\n",
      "\n",
      "\n",
      "[Test] Final Answer:\n",
      "Sorry bro, I couldn't find enough info to answer that confidently.\n"
     ]
    }
   ],
   "source": [
    "# rizzbot_agentic.py with logging\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableBranch\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents import AgentExecutor, Tool, initialize_agent, AgentType\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from langsmith import Client\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "class Rizzbot:\n",
    "    def __init__(self):\n",
    "        print(\"[INIT] Starting Rizzbot initialization...\")\n",
    "        _ = self._load_env()\n",
    "        self.similarity_threshold = 0.3\n",
    "        self.top_k = 3\n",
    "        self.summary_threshold = 2  # Stop after finding this many docs in summaries\n",
    "        self.min_docs_threshold = 2  # Minimum docs required to attempt answer generation\n",
    "\n",
    "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "        os.environ[\"LANGCHAIN_PROJECT\"] = \"rizzbot\"\n",
    "        print(\"[ENV] Environment variables set.\")\n",
    "\n",
    "        self.client = Client()\n",
    "\n",
    "        self.main_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.25)\n",
    "        print(\"[LLM] Main LLM (gpt-4o) initialized.\")\n",
    "\n",
    "        self.expand_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.6)\n",
    "        print(\"[LLM] Expansion LLM (gpt-3.5-turbo) initialized.\")\n",
    "\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        print(\"[Embeddings] OpenAI embeddings initialized.\")\n",
    "\n",
    "        self.pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "        print(\"[Pinecone] Pinecone client initialized.\")\n",
    "\n",
    "        self.summaries_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot-summaries-full-text\",\n",
    "            embedding=self.embeddings,\n",
    "            text_key=\"full_text\"\n",
    "        )\n",
    "        print(\"[VectorStore] Summaries vector store initialized.\")\n",
    "\n",
    "        self.full_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot\", embedding=self.embeddings, text_key=\"full_text\"\n",
    "        )\n",
    "        print(\"[VectorStore] Full vector store initialized.\")\n",
    "\n",
    "        self.no_answer_response = \"Sorry bro, I couldn't find enough info to answer that confidently.\"\n",
    "\n",
    "        self.base_prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a charisma and personal development expert helping someone improve their social skills.\n",
    "\n",
    "        Context: {content}\n",
    "        Question: {question}\n",
    "\n",
    "        Instructions:\n",
    "        1. Analyze the question and context. Check the vectorstores for an answer. If the answer can not be found in the vectorstore, answer: \"Sorry bro, I couldn't find enough info in my database to answer that confidently.\"\"\n",
    "        2. If the question is not clear, ask for clarification.\n",
    "        3. If the question is clear, provide actionable, specific advice based on the context.\n",
    "        4. Use examples when possible\n",
    "        5. Keep the tone encouraging and supportive\n",
    "        6. If information is insufficient, explain what you'd need to give a better answer\n",
    "        7. At the end of your response, include a \"Sources:\" section listing the document sources used\n",
    "\n",
    "        Response:\n",
    "        \"\"\")\n",
    "\n",
    "        self._build_agent_chain()\n",
    "        print(\"[INIT] Rizzbot initialized and ready.\")\n",
    "\n",
    "    def _load_env(self):\n",
    "        from dotenv import load_dotenv, find_dotenv\n",
    "        print(\"[ENV] Loading environment variables from .env file...\")\n",
    "        return load_dotenv(find_dotenv())\n",
    "\n",
    "    def _embed_question(self, question: str) -> List[float]:\n",
    "        print(f\"[Embed] Embedding question: {question}\")\n",
    "        result = self.embeddings.embed_query(question)\n",
    "        print(f\"[Embed] Embedding result length: {len(result)}\")\n",
    "        return result\n",
    "\n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "    def _filter_by_similarity(self, query_embedding, docs, threshold):\n",
    "        filtered = []\n",
    "        sources = []\n",
    "\n",
    "        for doc in docs:\n",
    "            try:\n",
    "                doc_embedding = self.embeddings.embed_query(doc.page_content)\n",
    "                sim = self._cosine_similarity(query_embedding, doc_embedding)\n",
    "                print(f\"[Similarity] Score: {sim:.4f} | Text: {doc.page_content[:80]}...\")\n",
    "\n",
    "                if sim >= threshold:\n",
    "                    filtered.append(doc)\n",
    "                    # Extract source information from document metadata\n",
    "                    source_info = self._extract_source_info(doc)\n",
    "                    sources.append(source_info)\n",
    "            except Exception as e:\n",
    "                print(f\"[Similarity] Failed to embed doc: {e}\")\n",
    "\n",
    "        return filtered, sources\n",
    "\n",
    "    def _extract_source_info(self, doc) -> str:\n",
    "        \"\"\"Extract source information from document metadata\"\"\"\n",
    "        if hasattr(doc, 'metadata') and doc.metadata:\n",
    "            # Try to get source information from metadata\n",
    "            source = doc.metadata.get('source', 'Unknown source')\n",
    "            title = doc.metadata.get('title', '')\n",
    "            if title:\n",
    "                return f\"{title} ({source})\"\n",
    "            else:\n",
    "                return source\n",
    "        else:\n",
    "            # Fallback to truncated content as identifier\n",
    "            return f\"Document: {doc.page_content[:50]}...\"\n",
    "\n",
    "    def _hybrid_query_search(self, question: str) -> Tuple[List[str], List[str]]:\n",
    "        print(f\"[Search:Hybrid] Embedding question...\")\n",
    "        question_embedding = self._embed_question(question)\n",
    "        combined_results = []\n",
    "        all_sources = []\n",
    "\n",
    "        # First, try summaries vectorstore\n",
    "        print(f\"[Search:Hybrid] Trying summaries vectorstore...\")\n",
    "        try:\n",
    "            retriever = MultiQueryRetriever.from_llm(\n",
    "                retriever=self.summaries_vectorstore.as_retriever(search_kwargs={\"k\": self.top_k}),\n",
    "                llm=self.expand_llm\n",
    "            )\n",
    "            docs = retriever.invoke(question)\n",
    "            filtered, sources = self._filter_by_similarity(question_embedding, docs, self.similarity_threshold)\n",
    "            print(f\"[Search:Hybrid] {len(filtered)} docs passed threshold in summaries.\")\n",
    "            \n",
    "            if len(filtered) > self.summary_threshold:\n",
    "                print(f\"[Search:Hybrid] Found {len(filtered)} docs in summaries (>{self.summary_threshold}), skipping full search.\")\n",
    "                combined_results.extend([doc.page_content for doc in filtered])\n",
    "                all_sources.extend(sources)\n",
    "                return combined_results, all_sources\n",
    "            else:\n",
    "                combined_results.extend([doc.page_content for doc in filtered])\n",
    "                all_sources.extend(sources)\n",
    "        except Exception as e:\n",
    "            print(f\"[Search:Hybrid] Retrieval failed for summaries: {e}\")\n",
    "\n",
    "        # If we didn't find enough in summaries, search full vectorstore\n",
    "        print(f\"[Search:Hybrid] Trying full vectorstore...\")\n",
    "        try:\n",
    "            retriever = MultiQueryRetriever.from_llm(\n",
    "                retriever=self.full_vectorstore.as_retriever(search_kwargs={\"k\": self.top_k}),\n",
    "                llm=self.expand_llm\n",
    "            )\n",
    "            docs = retriever.invoke(question)\n",
    "            filtered, sources = self._filter_by_similarity(question_embedding, docs, self.similarity_threshold)\n",
    "            print(f\"[Search:Hybrid] {len(filtered)} docs passed threshold in full.\")\n",
    "            combined_results.extend([doc.page_content for doc in filtered])\n",
    "            all_sources.extend(sources)\n",
    "        except Exception as e:\n",
    "            print(f\"[Search:Hybrid] Retrieval failed for full: {e}\")\n",
    "\n",
    "        return combined_results, all_sources\n",
    "\n",
    "    def _build_agent_chain(self):\n",
    "        print(\"[Chain] Building agent chain...\")\n",
    "\n",
    "        def format_content_with_sources(content_and_sources):\n",
    "            \"\"\"Format content with sources for the LLM\"\"\"\n",
    "            content, sources = content_and_sources\n",
    "            if content:\n",
    "                formatted_content = content\n",
    "                if sources:\n",
    "                    formatted_content += f\"\\n\\nSources: {', '.join(set(sources))}\"\n",
    "                return formatted_content\n",
    "            else:\n",
    "                return self.no_answer_response\n",
    "    \n",
    "        self.agent_chain = (\n",
    "            {\n",
    "                \"question\": lambda q: q,\n",
    "                \"content\": format_content_with_sources,\n",
    "            }\n",
    "            | self.base_prompt_template\n",
    "            | self.main_llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        print(\"[Chain] Agent chain constructed.\")\n",
    "\n",
    "    def answer_question(self, question: str) -> str:\n",
    "        print(f\"[Answer] Received question: {question}\")\n",
    "        try:\n",
    "            # Perform search once\n",
    "            context, sources = self._hybrid_query_search(question)\n",
    "            \n",
    "            # Check if we have enough documents\n",
    "            if not context or len(context) < self.min_docs_threshold:\n",
    "                print(f\"[Answer] Insufficient documents found ({len(context) if context else 0} docs, need {self.min_docs_threshold}). Returning fallback response.\")\n",
    "                return self.no_answer_response\n",
    "\n",
    "            print(f\"[Answer] Found {len(context)} relevant documents. Generating response with LLM...\")\n",
    "            \n",
    "            # Format content with sources\n",
    "            content_text = \"\\n\\n\".join(context)\n",
    "            if sources:\n",
    "                content_text += f\"\\n\\nSources: {', '.join(set(sources))}\"\n",
    "            \n",
    "            # Pass the pre-searched content to the chain\n",
    "            answer = self.agent_chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"content\": (content_text, sources)\n",
    "            })\n",
    "            \n",
    "            print(f\"[Answer] Answer generated successfully.\")\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"[Answer] Agentic pipeline failed: {e}\")\n",
    "            return self.no_answer_response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[Test] Starting test run for Rizzbot...\\n\")\n",
    "    \n",
    "    bot = Rizzbot()\n",
    "    sample_questions = [\"What is the capital of France?\"]\n",
    "\n",
    "    \n",
    "    for sample_question in sample_questions:\n",
    "        print(f\"\\n[Test] Asking: {sample_question}\\n\")\n",
    "        print(f\"[Test] Question: {sample_question}\")\n",
    "        answer = bot.answer_question(sample_question)\n",
    "        # save the answer to a .txt file\n",
    "        with open(\"test_answers.txt\", \"a\") as f:\n",
    "            f.write(f\"Question: {sample_question}\\nAnswer: {answer}\\n\\n\")\n",
    "        print(f\"[Test] Answer: {answer}\\n\")\n",
    "    print(\"[Test] All questions answered. Check test_answers.txt for results.\\n\")\n",
    "\n",
    "    print(\"\\n[Test] Final Answer:\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2168359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Convert] Converting test_answers.txt to test_answers.csv...\n",
      "[Convert] Conversion complete. Saved to test_answers.csv.\n"
     ]
    }
   ],
   "source": [
    "# Convert test_answers.txt to .csv file\n",
    "import pandas as pd\n",
    "def convert_txt_to_csv(txt_file: str, csv_file: str):\n",
    "    print(f\"[Convert] Converting {txt_file} to {csv_file}...\")\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for i in range(0, len(lines), 3):\n",
    "        question = lines[i].strip().replace(\"Question: \", \"\")\n",
    "        answer = lines[i + 1].strip().replace(\"Answer: \", \"\")\n",
    "        data.append({\"Question\": question, \"Answer\": answer})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"[Convert] Conversion complete. Saved to {csv_file}.\")\n",
    "convert_txt_to_csv(\"test_answers.txt\", \"test_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "380be110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             question  \\\n",
      "0   I have a presentation tomorrow, how can I impr...   \n",
      "1                     1. **Body Language and Space**:   \n",
      "2                     2. **Storytelling Techniques**:   \n",
      "3            3. **Confidence Through Vulnerability**:   \n",
      "4                 4. **Handling Awkward Situations**:   \n",
      "5                           5. **Active Engagement**:   \n",
      "6   6. **Preparation and Anticipation of Questions**:   \n",
      "7   Remember, the key to a successful presentation...   \n",
      "8   - Document discussing body language and storyt...   \n",
      "9   How can I make a good first impression on a date?   \n",
      "10  1. **Be Authentic**: Authenticity is key to ma...   \n",
      "11                                                NaN   \n",
      "12  4. **Compliment Without Overdoing It**: Compli...   \n",
      "13                                                NaN   \n",
      "14  7. **Prepare Conversation Starters**: Having a...   \n",
      "15                                                NaN   \n",
      "16  - Document on authenticity and avoiding excess...   \n",
      "17  What are some examples of behaviours that cele...   \n",
      "18  1. **Body Language and Space**: Celebrities li...   \n",
      "19                                                NaN   \n",
      "20  4. **Active Listening and Engagement**: Engagi...   \n",
      "21                                                NaN   \n",
      "22  7. **Handling Awkward Situations**: Acknowledg...   \n",
      "23                                                NaN   \n",
      "24                                           Sources:   \n",
      "25  - Document exploring Conor McGregor's charisma...   \n",
      "26  What can I do to my body language to feel more...   \n",
      "27  1. **Take Up Space**: Confidence is often conv...   \n",
      "28                                                NaN   \n",
      "29  4. **Practice Active Listening**: Engaging wit...   \n",
      "30                                                NaN   \n",
      "31  By incorporating these strategies into your in...   \n",
      "32                                      - Topic ID: 1   \n",
      "33                                                NaN   \n",
      "34                                                NaN   \n",
      "35  2. **Humor and Playfulness**: Incorporate humo...   \n",
      "36                                                NaN   \n",
      "37  5. **Confidence Through Vulnerability**: Be au...   \n",
      "38                                                NaN   \n",
      "39                                           Sources:   \n",
      "\n",
      "                                               answer  helpfulness  \\\n",
      "0   To improve your presence on stage for your pre...            1   \n",
      "1   - Use open and confident body language. Stand ...            4   \n",
      "2   - Incorporate storytelling into your presentat...            4   \n",
      "3   - Embrace vulnerability to build confidence. A...            5   \n",
      "4   - If you encounter any awkward moments during ...            5   \n",
      "5   - Engage with your audience by making eye cont...            5   \n",
      "6   - Prepare for potential questions or interrupt...            5   \n",
      "7                                                 NaN            1   \n",
      "8   - Document discussing handling awkward situati...            2   \n",
      "9   To make a good first impression on a date, it'...            3   \n",
      "10                                                NaN            1   \n",
      "11  3. **Use Effective Communication Techniques**:...            4   \n",
      "12                                                NaN            1   \n",
      "13  6. **Create a Safe and Comfortable Environment...            4   \n",
      "14                                                NaN            1   \n",
      "15                                           Sources:            1   \n",
      "16  - Document on creating a comfortable atmospher...            2   \n",
      "17  To answer the question about behaviors that ma...            4   \n",
      "18                                                NaN            1   \n",
      "19  3. **Teasing and Compliments**: A balance betw...            4   \n",
      "20                                                NaN            1   \n",
      "21  6. **Confidence Through Vulnerability**: Being...            4   \n",
      "22                                                NaN            1   \n",
      "23  These behaviors, when adopted, can enhance one...            2   \n",
      "24  - Document discussing techniques and habits of...            1   \n",
      "25  - Document on learning charisma and personal d...            2   \n",
      "26  To feel more confident through your body langu...            2   \n",
      "27                                                NaN            1   \n",
      "28  3. **Use Eye Contact and Smiling**: Eye contac...            4   \n",
      "29                                                NaN            1   \n",
      "30  6. **Embrace Vulnerability**: Confidence can a...            4   \n",
      "31                                                NaN            1   \n",
      "32                                     - Topic ID: 37            1   \n",
      "33    Question: How can I connect with people better?            1   \n",
      "34  1. **Body Language and Space**: Use open body ...            4   \n",
      "35                                                NaN            1   \n",
      "36  4. **Storytelling Techniques**: Enhance your c...            4   \n",
      "37                                                NaN            1   \n",
      "38  By adopting these strategies, you can improve ...            4   \n",
      "39                                    - e, c, n, t, o            1   \n",
      "\n",
      "    specificity  tone  groundedness  \\\n",
      "0             1     3             1   \n",
      "1             4     4             1   \n",
      "2             4     4             1   \n",
      "3             4     5             3   \n",
      "4             4     5             3   \n",
      "5             4     4             1   \n",
      "6             4     4             1   \n",
      "7             1     1             1   \n",
      "8             3     3             1   \n",
      "9             2     4             1   \n",
      "10            1     1             1   \n",
      "11            4     4             1   \n",
      "12            1     1             1   \n",
      "13            4     4             1   \n",
      "14            1     1             1   \n",
      "15            1     1             1   \n",
      "16            3     3             1   \n",
      "17            1     3             1   \n",
      "18            1     1             1   \n",
      "19            4     4             1   \n",
      "20            1     1             1   \n",
      "21            3     4             1   \n",
      "22            1     1             1   \n",
      "23            1     3             1   \n",
      "24            1     3             1   \n",
      "25            1     3             1   \n",
      "26            1     3             1   \n",
      "27            1     1             1   \n",
      "28            5     4             1   \n",
      "29            1     1             1   \n",
      "30            4     4             1   \n",
      "31            1     1             1   \n",
      "32            1     1             1   \n",
      "33            1     1             1   \n",
      "34            4     4             1   \n",
      "35            1     1             1   \n",
      "36            4     4             1   \n",
      "37            1     1             1   \n",
      "38            2     4             1   \n",
      "39            1     1             1   \n",
      "\n",
      "                                              comment  \n",
      "0   The AI response is incomplete and does not pro...  \n",
      "1   The advice is helpful and specific, with a goo...  \n",
      "2   The advice is helpful and specific, with a goo...  \n",
      "3   The advice is helpful and specific, with a goo...  \n",
      "4   The advice is helpful and specific, with a pos...  \n",
      "5   The advice is helpful and specific, with a pos...  \n",
      "6   The advice is very helpful and specific, with ...  \n",
      "7   The AI did not provide an answer, so it's impo...  \n",
      "8   The AI response does not align with the contex...  \n",
      "9   The advice is generally helpful and the tone i...  \n",
      "10                  The AI did not provide an answer.  \n",
      "11  The advice is helpful and specific, with a pos...  \n",
      "12  The AI did not provide an answer, so it's impo...  \n",
      "13  The advice is helpful and specific, with a goo...  \n",
      "14                  The AI did not provide an answer.  \n",
      "15  The AI response is incomplete and provides no ...  \n",
      "16  The advice is not helpful or grounded in the c...  \n",
      "17  The AI's response is helpful in setting up an ...  \n",
      "18  The AI did not provide an answer, so it's impo...  \n",
      "19  The advice is helpful and specific, with a goo...  \n",
      "20  The AI did not provide an answer, so it's impo...  \n",
      "21  The advice is helpful and has a positive tone,...  \n",
      "22  The AI did not provide an answer, so it's impo...  \n",
      "23  The advice lacks specificity and context. It i...  \n",
      "24  The response does not provide any advice or in...  \n",
      "25  The response lacks specificity and doesn't pro...  \n",
      "26  The answer lacks specific advice and doesn't p...  \n",
      "27  The AI did not provide an answer, so it's impo...  \n",
      "28  The advice is helpful and very specific, with ...  \n",
      "29  The AI did not provide an answer, so it's impo...  \n",
      "30  The advice is helpful and specific, with a goo...  \n",
      "31  The AI did not provide an answer, so it's impo...  \n",
      "32  The AI response does not provide any advice, l...  \n",
      "33      The AI did not provide an answer to evaluate.  \n",
      "34  The advice is helpful and specific, with a pos...  \n",
      "35  The AI did not provide an answer, so it's impo...  \n",
      "36  The advice is helpful and specific, with a pos...  \n",
      "37  The AI did not provide an answer, so it's impo...  \n",
      "38  The advice is helpful and the tone is encourag...  \n",
      "39  The response is not helpful, specific, or grou...  \n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "open_ai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize evaluator LLM (use a more critical model like gpt-4 if available)\n",
    "evaluator_llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0, api_key=open_ai_api_key)\n",
    "\n",
    "# Evaluation criteria prompt\n",
    "eval_prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert evaluator of communication advice.\n",
    "\n",
    "Evaluate the following AI-generated answer based on these criteria (rate each 1-5):\n",
    "- Helpfulness: Does it help the user improve charisma or social skill?\n",
    "- Specificity: Is the advice concrete and not generic?\n",
    "- Tone: Is it encouraging, empathetic, and natural?\n",
    "- Groundedness: Does it appear based on the context provided?\n",
    "\n",
    "Return your answer in JSON format like:\n",
    "{{\n",
    "  \"helpfulness\": 4,\n",
    "  \"specificity\": 3,\n",
    "  \"tone\": 5,\n",
    "  \"groundedness\": 2,\n",
    "  \"comment\": \"Good tone and practical advice, but lacks reference to context.\"\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "AI Answer:\n",
    "{answer}\n",
    "\"\"\")\n",
    "def evaluate_responses_from_csv(csv_file: str):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row[\"Question\"]\n",
    "        answer = row[\"Answer\"]\n",
    "        context = \"\"  # Adjust if you have context\n",
    "\n",
    "        prompt = eval_prompt_template.format(question=question, context=context, answer=answer)\n",
    "        response = evaluator_llm.predict(prompt)\n",
    "        try:\n",
    "            eval_result = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ Failed to parse response. Raw output:\")\n",
    "            print(response)\n",
    "            eval_result = {}\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            **eval_result\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    eval_results = evaluate_responses_from_csv(\"test_answers.csv\")\n",
    "    df_eval = pd.DataFrame(eval_results)\n",
    "    print(df_eval)\n",
    "    df_eval.to_csv(\"evaluation_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c691868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c991312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
