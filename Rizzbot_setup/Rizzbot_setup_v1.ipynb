{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2459a273",
   "metadata": {},
   "source": [
    "This notebook sets up the Agentic system.\n",
    "The simplified flow of the system is as follows:\n",
    "User gives input question as a prompt -> Preprocess the question via prompt tuning -> do a semantic search query over the summary database  -> \n",
    "\n",
    "(branch 1): is the answer in a summary (or spread over multiple)? -> use the summary/summaries to generate summary answer -> output answer to user\n",
    "\n",
    "(branch 2): is the answer not in a summary? -> semantic search query the entire dataset for the answer -> retrieve the relevant chunks -> generate summary of the relevant results -> output answer to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fddd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code implements the RAG system for the Agentic chatbot, called Rizzbot.\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pydantic import SecretStr\n",
    "from functools import lru_cache\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.schema import Document\n",
    "\n",
    "# LangSmith imports\n",
    "from langsmith import Client\n",
    "import langsmith\n",
    "\n",
    "# Pinecone\n",
    "import pinecone\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "# Initialize LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"rizzbot\"\n",
    "\n",
    "# Set up API keys\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"Container for search results\"\"\"\n",
    "    content: str\n",
    "    score: float\n",
    "    source: str\n",
    "    metadata: Dict = None\n",
    "\n",
    "class Rizzbot:\n",
    "    \"\"\"\n",
    "    Agentic chatbot system for charisma and personal development questions.\n",
    "    Uses RAG with Pinecone vector stores and AWS S3 for summaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the RAG system with all required components\"\"\"\n",
    "        self.similarity_threshold = 0.85\n",
    "        self.top_k = 3\n",
    "        \n",
    "        # Initialize summary cache\n",
    "        self.summary_cache = {}\n",
    "        self.cache_max_size = 100  # Maximum number of summaries to cache\n",
    "        self.cache_ttl = 3600  # Cache TTL in seconds (1 hour)\n",
    "        \n",
    "        # Initialize LangSmith client\n",
    "        self.langsmith_client = Client(api_key=langsmith_api_key)\n",
    "        \n",
    "        # Initialize OpenAI components\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.25,\n",
    "            api_key=openai_api_key,\n",
    "            tags=[\"rizzbot_v1\"]\n",
    "        )\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # Initialize Pinecone\n",
    "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
    "        \n",
    "        # Initialize vector stores\n",
    "        self._init_vector_stores()\n",
    "        \n",
    "        # Initialize AWS S3 client\n",
    "        self.s3_client = boto3.client(\"s3\")\n",
    "        \n",
    "        # Initialize prompts\n",
    "        self._init_prompts()\n",
    "    \n",
    "    def _init_vector_stores(self):\n",
    "        \"\"\"Initialize Pinecone vector stores\"\"\"\n",
    "        # Main dataset index - using full_text field\n",
    "        self.main_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot\",\n",
    "            embedding=self.embeddings,\n",
    "            text_key=\"full_text\"  # Specify the correct text field\n",
    "        )\n",
    "        \n",
    "        # Clusters index\n",
    "        self.clusters_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot-clusters\", \n",
    "            embedding=self.embeddings\n",
    "        )\n",
    "        \n",
    "        # Summaries index - will use S3 for full summaries\n",
    "        self.summaries_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot-summaries\",\n",
    "            embedding=self.embeddings\n",
    "        )\n",
    "    \n",
    "    def _init_prompts(self):\n",
    "        \"\"\"Initialize prompt templates\"\"\"\n",
    "        self.summary_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a charisma and personal development expert. Based on the following summary/summaries, \n",
    "        provide a comprehensive and helpful answer to the user's question.\n",
    "        \n",
    "        User Question: {question}\n",
    "        \n",
    "        Relevant Summary/Summaries:\n",
    "        {summaries}\n",
    "        \n",
    "        Instructions:\n",
    "        - Provide a clear, actionable answer based on the summaries\n",
    "        - Be conversational and engaging\n",
    "        - If the summaries don't fully address the question, mention this limitation\n",
    "        - Keep your response focused and practical\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        \n",
    "        self.full_search_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a charisma and personal development expert. Based on the following relevant content \n",
    "        from the database, provide a comprehensive and helpful answer to the user's question.\n",
    "        \n",
    "        User Question: {question}\n",
    "        \n",
    "        Relevant Content:\n",
    "        {content}\n",
    "        \n",
    "        Instructions:\n",
    "        - Synthesize the information to provide a clear, actionable answer\n",
    "        - Be conversational and engaging\n",
    "        - Focus on practical advice and insights\n",
    "        - If the content doesn't fully address the question, mention this limitation\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\")\n",
    "        \n",
    "        self.no_answer_response = \"\"\"My apologies, but I don't have a good answer for you based on the information in my database. My database is limited up to the past 5 years. For further research, we recommend you visit the source of my knowledge: https://www.youtube.com/user/Charismaoncommand/\"\"\"\n",
    "    \n",
    "    def _is_cache_valid(self, timestamp: float) -> bool:\n",
    "        \"\"\"Check if cache entry is still valid based on TTL\"\"\"\n",
    "        return time.time() - timestamp < self.cache_ttl\n",
    "    \n",
    "    def _clean_cache(self):\n",
    "        \"\"\"Remove expired entries and maintain cache size limit\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove expired entries\n",
    "        expired_keys = [\n",
    "            key for key, (_, timestamp) in self.summary_cache.items()\n",
    "            if not self._is_cache_valid(timestamp)\n",
    "        ]\n",
    "        for key in expired_keys:\n",
    "            del self.summary_cache[key]\n",
    "        \n",
    "        # If cache is still too large, remove oldest entries\n",
    "        if len(self.summary_cache) > self.cache_max_size:\n",
    "            # Sort by timestamp and remove oldest\n",
    "            sorted_items = sorted(\n",
    "                self.summary_cache.items(), \n",
    "                key=lambda x: x[1][1]  # Sort by timestamp\n",
    "            )\n",
    "            items_to_remove = len(self.summary_cache) - self.cache_max_size\n",
    "            for key, _ in sorted_items[:items_to_remove]:\n",
    "                del self.summary_cache[key]\n",
    "    \n",
    "    def _get_cached_summary(self, topic_id: int) -> Optional[str]:\n",
    "        \"\"\"Get summary from cache if available and valid\"\"\"\n",
    "        cache_key = f\"topic_{topic_id}\"\n",
    "        if cache_key in self.summary_cache:\n",
    "            summary, timestamp = self.summary_cache[cache_key]\n",
    "            if self._is_cache_valid(timestamp):\n",
    "                return summary\n",
    "            else:\n",
    "                # Remove expired entry\n",
    "                del self.summary_cache[cache_key]\n",
    "        return None\n",
    "    \n",
    "    def _cache_summary(self, topic_id: int, summary: str):\n",
    "        \"\"\"Add summary to cache\"\"\"\n",
    "        self._clean_cache()  # Clean cache before adding new entry\n",
    "        cache_key = f\"topic_{topic_id}\"\n",
    "        self.summary_cache[cache_key] = (summary, time.time())\n",
    "    \n",
    "    def _fetch_single_summary_from_s3(self, topic_id: int) -> Optional[str]:\n",
    "        \"\"\"Fetch a single summary from S3\"\"\"\n",
    "        bucket_name = \"rizzbot-temp-storage\"\n",
    "        base_path = \"rizzbot/Summaries/summaries_1kwords/\"\n",
    "        \n",
    "        try:\n",
    "            key = f\"{base_path}topic_{topic_id}.json\"\n",
    "            response = self.s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "            content = response['Body'].read().decode('utf-8')\n",
    "            # Handle both JSON and plain text formats\n",
    "            summary_text = json.loads(content) if content.startswith('{') else content\n",
    "            return str(summary_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not retrieve topic_{topic_id}.json: {e}\")\n",
    "            return None\n",
    "    def search_summaries(self, question: str) -> List[SearchResult]:\n",
    "        \"\"\"Search in the summaries index\"\"\"\n",
    "        try:\n",
    "            results = self.summaries_vectorstore.similarity_search_with_score(\n",
    "                question, \n",
    "                k=self.top_k,\n",
    "                filter=None  # Could add topic_id filtering here if needed\n",
    "            )\n",
    "            \n",
    "            search_results = []\n",
    "            for doc, score in results:\n",
    "                if score >= self.similarity_threshold:\n",
    "                    search_results.append(SearchResult(\n",
    "                        content=doc.page_content,\n",
    "                        score=score,\n",
    "                        source=\"summary\",\n",
    "                        metadata=doc.metadata\n",
    "                    ))\n",
    "            \n",
    "            return search_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching summaries: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def search_full_dataset(self, question: str) -> List[SearchResult]:\n",
    "        \"\"\"Search in the full dataset index\"\"\"\n",
    "        try:\n",
    "            results = self.main_vectorstore.similarity_search_with_score(\n",
    "                question, \n",
    "                k=self.top_k\n",
    "            )\n",
    "            \n",
    "            search_results = []\n",
    "            for doc, score in results:\n",
    "                search_results.append(SearchResult(\n",
    "                    content=doc.page_content,\n",
    "                    score=score,\n",
    "                    source=\"full_dataset\",\n",
    "                    metadata=doc.metadata\n",
    "                ))\n",
    "            \n",
    "            return search_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching full dataset: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def get_s3_summaries(self, topic_ids: List[int]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve summaries with caching and batching optimizations\n",
    "        \n",
    "        Args:\n",
    "            topic_ids: List of topic IDs to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of summary texts\n",
    "        \"\"\"\n",
    "        summaries = []\n",
    "        uncached_ids = []\n",
    "        \n",
    "        # Step 1: Check cache for existing summaries\n",
    "        for topic_id in topic_ids:\n",
    "            cached_summary = self._get_cached_summary(topic_id)\n",
    "            if cached_summary:\n",
    "                summaries.append(cached_summary)\n",
    "                print(f\"Retrieved topic_{topic_id} from cache\")\n",
    "            else:\n",
    "                uncached_ids.append(topic_id)\n",
    "        \n",
    "        # Step 2: Batch fetch uncached summaries from S3\n",
    "        if uncached_ids:\n",
    "            print(f\"Fetching {len(uncached_ids)} summaries from S3...\")\n",
    "            \n",
    "            # Use ThreadPoolExecutor for concurrent S3 requests\n",
    "            with ThreadPoolExecutor(max_workers=min(len(uncached_ids), 5)) as executor:\n",
    "                # Submit all fetch tasks\n",
    "                future_to_topic = {\n",
    "                    executor.submit(self._fetch_single_summary_from_s3, topic_id): topic_id\n",
    "                    for topic_id in uncached_ids\n",
    "                }\n",
    "                \n",
    "                # Collect results as they complete\n",
    "                for future in as_completed(future_to_topic):\n",
    "                    topic_id = future_to_topic[future]\n",
    "                    try:\n",
    "                        summary = future.result()\n",
    "                        if summary:\n",
    "                            summaries.append(summary)\n",
    "                            # Cache the retrieved summary\n",
    "                            self._cache_summary(topic_id, summary)\n",
    "                            print(f\"Retrieved and cached topic_{topic_id}\")\n",
    "                        else:\n",
    "                            print(f\"Failed to retrieve topic_{topic_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching topic_{topic_id}: {e}\")\n",
    "        \n",
    "        print(f\"Total summaries retrieved: {len(summaries)}\")\n",
    "        return summaries\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def generate_summary_answer(self, question: str, summaries: List[str]) -> str:\n",
    "        \"\"\"Generate answer based on summaries\"\"\"\n",
    "        combined_summaries = \"\\n\\n\".join(summaries)\n",
    "        \n",
    "        chain = self.summary_answer_prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"summaries\": combined_summaries\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def generate_full_search_answer(self, question: str, search_results: List[SearchResult]) -> str:\n",
    "        \"\"\"Generate answer based on full dataset search results\"\"\"\n",
    "        combined_content = \"\\n\\n\".join([result.content for result in search_results])\n",
    "        \n",
    "        chain = self.full_search_answer_prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "        response = chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"content\": combined_content\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    @langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "    def answer_question(self, question: str) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Main method to answer user questions following the RAG flow\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing answer, source, and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Step 1: Search summaries\n",
    "            print(\"Searching summaries...\")\n",
    "            summary_results = self.search_summaries(question)\n",
    "            \n",
    "            if summary_results:\n",
    "                print(f\"Found {len(summary_results)} relevant summaries\")\n",
    "                \n",
    "                # Extract topic IDs if available in metadata\n",
    "                topic_ids = []\n",
    "                for result in summary_results:\n",
    "                    if result.metadata and 'topic_id' in result.metadata:\n",
    "                        topic_ids.append(result.metadata['topic_id'])\n",
    "                \n",
    "                # Get full summaries from S3 if topic_ids available\n",
    "                if topic_ids:\n",
    "                    full_summaries = self.get_s3_summaries(topic_ids)\n",
    "                    if full_summaries:\n",
    "                        answer = self.generate_summary_answer(question, full_summaries)\n",
    "                        return {\n",
    "                            \"answer\": answer,\n",
    "                            \"source\": \"summaries\",\n",
    "                            \"num_sources\": len(full_summaries),\n",
    "                            \"confidence_scores\": [r.score for r in summary_results]\n",
    "                        }\n",
    "                \n",
    "                # Fallback: use summary search results directly\n",
    "                summaries = [result.content for result in summary_results]\n",
    "                answer = self.generate_summary_answer(question, summaries)\n",
    "                return {\n",
    "                    \"answer\": answer,\n",
    "                    \"source\": \"summaries\",\n",
    "                    \"num_sources\": len(summaries),\n",
    "                    \"confidence_scores\": [r.score for r in summary_results]\n",
    "                }\n",
    "            \n",
    "            # Step 2: Search full dataset\n",
    "            print(\"Searching full dataset...\")\n",
    "            full_results = self.search_full_dataset(question)\n",
    "            \n",
    "            if full_results:\n",
    "                print(f\"Found {len(full_results)} relevant chunks\")\n",
    "                answer = self.generate_full_search_answer(question, full_results)\n",
    "                return {\n",
    "                    \"answer\": answer,\n",
    "                    \"source\": \"full_dataset\", \n",
    "                    \"num_sources\": len(full_results),\n",
    "                    \"confidence_scores\": [r.score for r in full_results]\n",
    "                }\n",
    "            \n",
    "            # Step 3: No relevant results found\n",
    "            print(\"No relevant results found\")\n",
    "            return {\n",
    "                \"answer\": self.no_answer_response,\n",
    "                \"source\": \"none\",\n",
    "                \"num_sources\": 0,\n",
    "                \"confidence_scores\": []\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in answer_question: {e}\")\n",
    "            return {\n",
    "                \"answer\": self.no_answer_response,\n",
    "                \"source\": \"error\",\n",
    "                \"num_sources\": 0,\n",
    "                \"confidence_scores\": [],\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "# Convenience function for easy usage\n",
    "def create_rizzbot():\n",
    "    \"\"\"Factory function to create and return a Rizzbot instance\"\"\"\n",
    "    return Rizzbot()\n",
    "\n",
    "# Example usage function\n",
    "@langsmith.traceable(tags=[\"rizzbot_v1\"])\n",
    "def ask_charisma_question(bot: Rizzbot, question: str, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Ask a question to the charisma bot and get a formatted response\n",
    "    \n",
    "    Args:\n",
    "        bot: Rizzbot instance\n",
    "        question: User's question\n",
    "        verbose: Whether to print detailed information\n",
    "    \n",
    "    Returns:\n",
    "        Dict with answer and metadata\n",
    "    \"\"\"\n",
    "    result = bot.answer_question(question)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(f\"\\n Metadata:\")\n",
    "        print(f\"  Source: {result['source']}\")\n",
    "        print(f\"  Number of sources: {result['num_sources']}\")\n",
    "        if result['confidence_scores']:\n",
    "            print(f\"  Confidence scores: {[f'{score:.3f}' for score in result['confidence_scores']]}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380be110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Rizzbot System...\n",
      "System ready!\n",
      "Searching summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching full dataset...\n",
      "Found 3 relevant chunks\n",
      "\n",
      "==================================================\n",
      "Question: Can you give me advice on how to be a better public speaker?\n",
      "==================================================\n",
      "Answer: Becoming a better public speaker is a journey that involves building confidence, honing your delivery skills, and connecting with your audience. Here are some practical tips to help you improve your public speaking abilities:\n",
      "\n",
      "1. **Build Confidence**: Confidence is key when it comes to public speaking. One way to boost your confidence is by practicing regularly. Consider joining a program like Charisma University, which offers a structured, step-by-step guide to enhance your charisma and confidence. As shared by a member, this program helped her transform from a nervous speaker to someone who could command a room of over 2,000 business owners.\n",
      "\n",
      "2. **Know Your Material**: Being well-prepared with your content can significantly reduce anxiety. Make sure you understand your topic thoroughly and can discuss it without relying heavily on notes. This will make you appear more knowledgeable and engaging.\n",
      "\n",
      "3. **Engage with Your Audience**: Building rapport with your audience can make your speech more impactful. Try to make eye contact, use gestures, and involve your audience through questions or interactive segments. The more you connect with them, the more they will be interested in what you have to say.\n",
      "\n",
      "4. **Practice Active Listening**: While public speaking is about delivering a message, being a good listener can help you respond better to audience reactions and questions. This skill can also be developed through programs like Charisma University, which emphasizes creating rapport and engaging effectively with others.\n",
      "\n",
      "5. **Seek Feedback and Reflect**: After each speaking engagement, seek feedback from trusted peers or mentors. Reflect on what went well and what could be improved. Continuous learning and adaptation are crucial for growth.\n",
      "\n",
      "6. **Visualize Success**: Before stepping on stage, visualize yourself succeeding. Picture the audience responding positively to your message. This mental rehearsal can help reduce anxiety and boost your confidence.\n",
      "\n",
      "While these tips provide a solid foundation, remember that public speaking is a skill that improves with practice and experience. If you're looking for a more structured approach, consider exploring courses like Charisma University, which has helped many individuals enhance their speaking skills and overall charisma. Keep practicing, stay open to learning, and you'll see improvement over time.\n",
      "\n",
      " Metadata:\n",
      "  Source: full_dataset\n",
      "  Number of sources: 3\n",
      "  Confidence scores: ['0.056', '0.038', '0.038']\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo cell \n",
    "# Demo: How to use the Rizzbot System\n",
    "# Run this in a Jupyter notebook cell after the main system code\n",
    "\n",
    "# Initialize the bot (this will take a moment as it connects to all services)\n",
    "print(\"Initializing Rizzbot System...\")\n",
    "bot = create_rizzbot()\n",
    "print(\"System ready!\")\n",
    "\n",
    "# Test questions\n",
    "test_questions = [\n",
    "    \"Can you give me advice on how to be a better public speaker?\"\n",
    "]\n",
    "\n",
    "# Test the system with different questions\n",
    "for question in test_questions:\n",
    "    result = ask_charisma_question(bot, question, verbose=True)\n",
    "    \n",
    "    # You can also access individual components:\n",
    "    # print(f\"Just the answer: {result['answer']}\")\n",
    "    # print(f\"Source type: {result['source']}\")\n",
    "\n",
    "# You can also use the bot directly for more control:\n",
    "# custom_result = bot.answer_question(\"Your custom question here\")\n",
    "# print(custom_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
