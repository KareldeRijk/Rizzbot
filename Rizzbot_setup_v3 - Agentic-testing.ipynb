{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2459a273",
   "metadata": {},
   "source": [
    "This notebook sets up the Agentic system.\n",
    "The simplified flow of the system is as follows:\n",
    "User gives input question as a prompt -> Preprocess the question via prompt tuning -> do a semantic search query over the summary database  -> \n",
    "\n",
    "(branch 1): is the answer in a summary (or spread over multiple)? -> use the summary/summaries to generate summary answer -> output answer to user\n",
    "\n",
    "(branch 2): is the answer not in a summary? -> semantic search query the entire dataset for the answer -> retrieve the relevant chunks -> generate summary of the relevant results -> output answer to user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fddd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Starting test run for Rizzbot...\n",
      "\n",
      "[INIT] Starting Rizzbot initialization...\n",
      "[ENV] Loading environment variables from .env file...\n",
      "[ENV] Environment variables set.\n",
      "[LLM] Main LLM (gpt-4o) initialized.\n",
      "[LLM] Expansion LLM (gpt-3.5-turbo) initialized.\n",
      "[Embeddings] OpenAI embeddings initialized.\n",
      "[Pinecone] Pinecone client initialized.\n",
      "[VectorStore] Summaries vector store initialized.\n",
      "[VectorStore] Full vector store initialized.\n",
      "[Chain] Building agent chain...\n",
      "[Chain] Agent chain constructed.\n",
      "[INIT] Rizzbot initialized and ready.\n",
      "\n",
      "[Test] Asking: Please tell me about the benefits of Charisma University?\n",
      "\n",
      "[Answer] Received question: Please tell me about the benefits of Charisma University?\n",
      "[Search:Hybrid] Embedding question...\n",
      "[Embed] Embedding question: Please tell me about the benefits of Charisma University?\n",
      "[Embed] Embedding result length: 1536\n",
      "[Search:Hybrid] Trying summaries vectorstore...\n",
      "[Similarity] Score: 0.4551 | Text: Topic ID: 17\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.4128 | Text: Topic ID: 47\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.3608 | Text: Topic ID: 27\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.3068 | Text: Topic ID: 49\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Similarity] Score: 0.3473 | Text: Topic ID: 28\n",
      "Run Name: 1000word_summaries_20250702_132026\n",
      "Target Words: 1000\n",
      "Tim...\n",
      "[Search:Hybrid] 0 docs passed threshold in summaries.\n",
      "[Search:Hybrid] Trying full vectorstore...\n",
      "[Similarity] Score: 0.2088 | Text:  me all wound up. I'm afraid something's gonna slip and my palms are sweaty. Com...\n",
      "[Similarity] Score: 0.2878 | Text:  in order to do that, just go to the most recent podcast that we find. You can f...\n",
      "[Similarity] Score: 0.1268 | Text:  more, go ahead, click the button on screen now or the link in the description. ...\n",
      "[Similarity] Score: 0.1302 | Text: 't retract it. You can't persuade. You have to go, I apologize. There's two dire...\n",
      "[Similarity] Score: 0.1310 | Text: Today you'll learn six easy ways to make people laugh and love being around you....\n",
      "[Similarity] Score: 0.5865 | Text: , you can give yourself a full refund from right inside the program. If you want...\n",
      "[Similarity] Score: 0.3049 | Text: -back guarantee which is 100% for any reason at all. And I make it 60 days even ...\n",
      "[Similarity] Score: 0.3106 | Text:  days because I want to make sure that every single person truly feels like they...\n",
      "[Search:Hybrid] 1 docs passed threshold in full.\n",
      "[Answer] Found 1 relevant documents. Generating response with LLM...\n",
      "[Answer] Answer generated successfully.\n",
      "\n",
      "[Test] Final Answer:\n",
      "Sorry bro, I couldn't find enough info in my database to answer that confidently. If you have more specific questions or details about Charisma University, feel free to share them, and I'll do my best to help you out!\n",
      "\n",
      "Sources: None\n"
     ]
    }
   ],
   "source": [
    "# rizzbot_agentic.py with logging\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableBranch\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents import AgentExecutor, Tool, initialize_agent, AgentType\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from langsmith import Client\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "class Rizzbot:\n",
    "    def __init__(self):\n",
    "        print(\"[INIT] Starting Rizzbot initialization...\")\n",
    "        _ = self._load_env()\n",
    "        self.similarity_threshold = 0.5\n",
    "        self.top_k = 3\n",
    "        self.summary_threshold = 2  # Stop after finding this many docs in summaries\n",
    "        self.min_docs_threshold = 2  # Minimum docs required to attempt answer generation\n",
    "\n",
    "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "        os.environ[\"LANGCHAIN_PROJECT\"] = \"rizzbot\"\n",
    "        print(\"[ENV] Environment variables set.\")\n",
    "\n",
    "        self.client = Client()\n",
    "\n",
    "        self.main_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.25)\n",
    "        print(\"[LLM] Main LLM (gpt-4o) initialized.\")\n",
    "\n",
    "        self.expand_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.6)\n",
    "        print(\"[LLM] Expansion LLM (gpt-3.5-turbo) initialized.\")\n",
    "\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        print(\"[Embeddings] OpenAI embeddings initialized.\")\n",
    "\n",
    "        self.pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "        print(\"[Pinecone] Pinecone client initialized.\")\n",
    "\n",
    "        self.summaries_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot-summaries-full-text\",\n",
    "            embedding=self.embeddings,\n",
    "            text_key=\"full_text\"\n",
    "        )\n",
    "        print(\"[VectorStore] Summaries vector store initialized.\")\n",
    "\n",
    "        self.full_vectorstore = PineconeVectorStore(\n",
    "            index_name=\"rizzbot\", embedding=self.embeddings, text_key=\"full_text\"\n",
    "        )\n",
    "        print(\"[VectorStore] Full vector store initialized.\")\n",
    "\n",
    "        self.no_answer_response = \"Sorry bro, I couldn't find enough info to answer that confidently.\"\n",
    "\n",
    "        self.base_prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a charisma and personal development expert helping someone improve their social skills.\n",
    "\n",
    "        Context: {content}\n",
    "        Question: {question}\n",
    "\n",
    "        Instructions:\n",
    "        1. Analyze the question and context. Check the vectorstores for an answer. If the answer can not be found in the vectorstore, answer: \"Sorry bro, I couldn't find enough info in my database to answer that confidently.\"\"\n",
    "        2. If the question is not clear, ask for clarification.\n",
    "        3. If the question is clear, provide actionable, specific advice based on the context.\n",
    "        4. Use examples when possible\n",
    "        5. Keep the tone encouraging and supportive\n",
    "        6. If information is insufficient, explain what you'd need to give a better answer\n",
    "        7. At the end of your response, include a \"Sources:\" section listing the document sources used\n",
    "\n",
    "        Response:\n",
    "        \"\"\")\n",
    "\n",
    "        self._build_agent_chain()\n",
    "        print(\"[INIT] Rizzbot initialized and ready.\")\n",
    "\n",
    "    def _load_env(self):\n",
    "        from dotenv import load_dotenv, find_dotenv\n",
    "        print(\"[ENV] Loading environment variables from .env file...\")\n",
    "        return load_dotenv(find_dotenv())\n",
    "\n",
    "    def _embed_question(self, question: str) -> List[float]:\n",
    "        print(f\"[Embed] Embedding question: {question}\")\n",
    "        result = self.embeddings.embed_query(question)\n",
    "        print(f\"[Embed] Embedding result length: {len(result)}\")\n",
    "        return result\n",
    "\n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "    def _filter_by_similarity(self, query_embedding, docs, threshold):\n",
    "        filtered = []\n",
    "        sources = []\n",
    "\n",
    "        for doc in docs:\n",
    "            try:\n",
    "                doc_embedding = self.embeddings.embed_query(doc.page_content)\n",
    "                sim = self._cosine_similarity(query_embedding, doc_embedding)\n",
    "                print(f\"[Similarity] Score: {sim:.4f} | Text: {doc.page_content[:80]}...\")\n",
    "\n",
    "                if sim >= threshold:\n",
    "                    filtered.append(doc)\n",
    "                    # Extract source information from document metadata\n",
    "                    source_info = self._extract_source_info(doc)\n",
    "                    sources.append(source_info)\n",
    "            except Exception as e:\n",
    "                print(f\"[Similarity] Failed to embed doc: {e}\")\n",
    "\n",
    "        return filtered, sources\n",
    "\n",
    "    def _extract_source_info(self, doc) -> str:\n",
    "        \"\"\"Extract source information from document metadata\"\"\"\n",
    "        if hasattr(doc, 'metadata') and doc.metadata:\n",
    "            # Try to get source information from metadata\n",
    "            source = doc.metadata.get('source', 'Unknown source')\n",
    "            title = doc.metadata.get('title', '')\n",
    "            if title:\n",
    "                return f\"{title} ({source})\"\n",
    "            else:\n",
    "                return source\n",
    "        else:\n",
    "            # Fallback to truncated content as identifier\n",
    "            return f\"Document: {doc.page_content[:50]}...\"\n",
    "\n",
    "    def _hybrid_query_search(self, question: str) -> Tuple[List[str], List[str]]:\n",
    "        print(f\"[Search:Hybrid] Embedding question...\")\n",
    "        question_embedding = self._embed_question(question)\n",
    "        combined_results = []\n",
    "        all_sources = []\n",
    "\n",
    "        # First, try summaries vectorstore\n",
    "        print(f\"[Search:Hybrid] Trying summaries vectorstore...\")\n",
    "        try:\n",
    "            retriever = MultiQueryRetriever.from_llm(\n",
    "                retriever=self.summaries_vectorstore.as_retriever(search_kwargs={\"k\": self.top_k}),\n",
    "                llm=self.expand_llm\n",
    "            )\n",
    "            docs = retriever.invoke(question)\n",
    "            filtered, sources = self._filter_by_similarity(question_embedding, docs, self.similarity_threshold)\n",
    "            print(f\"[Search:Hybrid] {len(filtered)} docs passed threshold in summaries.\")\n",
    "            \n",
    "            if len(filtered) > self.summary_threshold:\n",
    "                print(f\"[Search:Hybrid] Found {len(filtered)} docs in summaries (>{self.summary_threshold}), skipping full search.\")\n",
    "                combined_results.extend([doc.page_content for doc in filtered])\n",
    "                all_sources.extend(sources)\n",
    "                return combined_results, all_sources\n",
    "            else:\n",
    "                combined_results.extend([doc.page_content for doc in filtered])\n",
    "                all_sources.extend(sources)\n",
    "        except Exception as e:\n",
    "            print(f\"[Search:Hybrid] Retrieval failed for summaries: {e}\")\n",
    "\n",
    "        # If we didn't find enough in summaries, search full vectorstore\n",
    "        print(f\"[Search:Hybrid] Trying full vectorstore...\")\n",
    "        try:\n",
    "            retriever = MultiQueryRetriever.from_llm(\n",
    "                retriever=self.full_vectorstore.as_retriever(search_kwargs={\"k\": self.top_k}),\n",
    "                llm=self.expand_llm\n",
    "            )\n",
    "            docs = retriever.invoke(question)\n",
    "            filtered, sources = self._filter_by_similarity(question_embedding, docs, self.similarity_threshold)\n",
    "            print(f\"[Search:Hybrid] {len(filtered)} docs passed threshold in full.\")\n",
    "            combined_results.extend([doc.page_content for doc in filtered])\n",
    "            all_sources.extend(sources)\n",
    "        except Exception as e:\n",
    "            print(f\"[Search:Hybrid] Retrieval failed for full: {e}\")\n",
    "\n",
    "        return combined_results, all_sources\n",
    "\n",
    "    def _build_agent_chain(self):\n",
    "        print(\"[Chain] Building agent chain...\")\n",
    "\n",
    "        def format_content_with_sources(content_and_sources):\n",
    "            \"\"\"Format content with sources for the LLM\"\"\"\n",
    "            content, sources = content_and_sources\n",
    "            if content:\n",
    "                formatted_content = content\n",
    "                if sources:\n",
    "                    formatted_content += f\"\\n\\nSources: {', '.join(set(sources))}\"\n",
    "                return formatted_content\n",
    "            else:\n",
    "                return self.no_answer_response\n",
    "    \n",
    "        self.agent_chain = (\n",
    "            {\n",
    "                \"question\": lambda q: q,\n",
    "                \"content\": format_content_with_sources,\n",
    "            }\n",
    "            | self.base_prompt_template\n",
    "            | self.main_llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        print(\"[Chain] Agent chain constructed.\")\n",
    "\n",
    "    def answer_question(self, question: str) -> str:\n",
    "        print(f\"[Answer] Received question: {question}\")\n",
    "        try:\n",
    "            # Perform search once\n",
    "            context, sources = self._hybrid_query_search(question)\n",
    "            \n",
    "            # Check if we have enough documents\n",
    "            if not context or len(context) < self.min_docs_threshold:\n",
    "                print(f\"[Answer] Insufficient documents found ({len(context) if context else 0} docs, need {self.min_docs_threshold}). Returning fallback response.\")\n",
    "                return self.no_answer_response\n",
    "\n",
    "            print(f\"[Answer] Found {len(context)} relevant documents. Generating response with LLM...\")\n",
    "            \n",
    "            # Format content with sources\n",
    "            content_text = \"\\n\\n\".join(context)\n",
    "            if sources:\n",
    "                content_text += f\"\\n\\nSources: {', '.join(set(sources))}\"\n",
    "            \n",
    "            # Pass the pre-searched content to the chain\n",
    "            answer = self.agent_chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"content\": (content_text, sources)\n",
    "            })\n",
    "            \n",
    "            print(f\"[Answer] Answer generated successfully.\")\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"[Answer] Agentic pipeline failed: {e}\")\n",
    "            return self.no_answer_response\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[Test] Starting test run for Rizzbot...\\n\")\n",
    "    \n",
    "    bot = Rizzbot()\n",
    "    sample_question = \"Please tell me about the benefits of Charisma University?\"\n",
    "\n",
    "    print(f\"\\n[Test] Asking: {sample_question}\\n\")\n",
    "    answer = bot.answer_question(sample_question)\n",
    "\n",
    "    print(\"\\n[Test] Final Answer:\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380be110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain Output:\n",
      " David Dobrik's popularity can be attributed to several key factors that you can incorporate into your own social interactions to enhance your charisma and personal appeal. Here’s how you can apply these principles:\n",
      "\n",
      "1. **Embrace Humor**:\n",
      "   - **Actionable Advice**: Incorporate humor into your interactions. Don't be afraid to share funny stories or make light-hearted jokes, even if they are a bit silly. Laughter creates a shared experience that strengthens bonds.\n",
      "   - **Example**: If you’re in a group setting, share a humorous anecdote from your day. For instance, if you tripped over your shoelaces, you might say, “I was practicing my dance moves today and the floor decided to join in.”\n",
      "\n",
      "2. **Be Authentic**:\n",
      "   - **Actionable Advice**: Present your true self rather than a polished version. Authenticity is relatable and endearing. Engage with others from a place of joy and confidence.\n",
      "   - **Example**: If you’re passionate about a hobby, talk about it with enthusiasm. Let your genuine excitement shine through, as this can be contagious and engaging.\n",
      "\n",
      "3. **Use Self-Deprecating Humor**:\n",
      "   - **Actionable Advice**: Share stories where you can laugh at yourself. This can make you more relatable and approachable, but ensure it comes from a place of confidence, not insecurity.\n",
      "   - **Example**: If you made a mistake at work, you might say, “I’m pretty sure I invented a new way to mess up a spreadsheet today. I’m expecting a call from the Guinness World Records any minute now.”\n",
      "\n",
      "4. **Highlight Others**:\n",
      "   - **Actionable Advice**: Focus on the people around you. Celebrate their successes and contributions. This not only makes others feel valued but also creates a supportive community.\n",
      "   - **Example**: If a friend achieves something, like a promotion or a personal goal, take the time to congratulate them publicly, perhaps with a heartfelt social media post or a toast at a gathering.\n",
      "\n",
      "5. **Find Joy in Others’ Happiness**:\n",
      "   - **Actionable Advice**: Derive genuine joy from making others happy, rather than seeking validation. This mindset fosters authentic relationships.\n",
      "   - **Example**: If you’re hosting a gathering, focus on creating an enjoyable experience for your guests, whether it’s through thoughtful conversation, games, or simply ensuring everyone feels included.\n",
      "\n",
      "6. **Use High-Impact Language**:\n",
      "   - **Actionable Advice**: Express your feelings with enthusiasm and positivity. Avoid neutral language; instead, convey your genuine emotions.\n",
      "   - **Example**: Instead of saying, “That’s nice,” you could say, “That’s amazing! I’m so thrilled for you!”\n",
      "\n",
      "7. **Create a Positive Environment**:\n",
      "   - **Actionable Advice**: Prime yourself with positive and lighthearted content before social interactions. This can help you maintain a relaxed and enjoyable demeanor.\n",
      "   - **Example**: Watch a funny video or listen to upbeat music before attending a social event to boost your mood and energy.\n",
      "\n",
      "By integrating these strategies into your social interactions, you can enhance your charisma and build more meaningful connections, much like David Dobrik. Remember, the key is to be genuine and enjoy the process of connecting with others.\n",
      "Chain Output:\n",
      " Masculine archetypes are symbolic figures that represent different aspects of masculinity. These archetypes can guide personal development and help individuals understand and embody different facets of their personality. The key masculine archetypes often discussed include the King, Warrior, Magician, and Lover. Each of these archetypes can relate to charisma in unique ways, offering pathways to enhance one's social presence and interpersonal skills.\n",
      "\n",
      "### 1. The King\n",
      "**Characteristics**: Leadership, authority, responsibility, and benevolence.\n",
      "**Relation to Charisma**: The King archetype embodies a sense of calm authority and confidence, which are crucial components of charisma. A charismatic leader is someone who can inspire and motivate others, often through a strong sense of purpose and vision.\n",
      "\n",
      "**Actionable Advice**:\n",
      "- **Practice Decision-Making**: Take charge in situations where you can make decisions, even in small group settings. This builds confidence and demonstrates leadership.\n",
      "- **Cultivate Empathy**: Show genuine concern for others' well-being. This can be as simple as actively listening to someone’s concerns and offering support.\n",
      "\n",
      "### 2. The Warrior\n",
      "**Characteristics**: Courage, discipline, assertiveness, and focus.\n",
      "**Relation to Charisma**: The Warrior archetype is about taking action and standing up for one's beliefs, which can be very charismatic. People are often drawn to those who are assertive and confident in their actions.\n",
      "\n",
      "**Actionable Advice**:\n",
      "- **Set Clear Boundaries**: Learn to say no when necessary and stand firm in your decisions. This assertiveness can enhance your presence and respect from others.\n",
      "- **Channel Aggression Positively**: Engage in physical activities like sports or martial arts to channel energy constructively, which can improve your focus and discipline.\n",
      "\n",
      "### 3. The Magician\n",
      "**Characteristics**: Wisdom, insight, transformation, and creativity.\n",
      "**Relation to Charisma**: The Magician archetype is about understanding and transforming situations, which can be very appealing. Charismatic individuals often have a knack for seeing things differently and offering new perspectives.\n",
      "\n",
      "**Actionable Advice**:\n",
      "- **Expand Your Knowledge**: Read widely and engage in activities that stimulate your mind. Being knowledgeable makes you more interesting and engaging in conversations.\n",
      "- **Practice Storytelling**: Use stories to convey your ideas and insights. A well-told story can captivate an audience and make your message more memorable.\n",
      "\n",
      "### 4. The Lover\n",
      "**Characteristics**: Passion, connection, empathy, and sensuality.\n",
      "**Relation to Charisma**: The Lover archetype is about forming deep connections and expressing emotions, which are key to genuine charisma. People are drawn to those who are warm and empathetic.\n",
      "\n",
      "**Actionable Advice**:\n",
      "- **Enhance Emotional Intelligence**: Pay attention to your emotions and those of others. Practice empathy by trying to understand others' perspectives and feelings.\n",
      "- **Engage in Active Listening**: Show genuine interest in others by listening attentively and responding thoughtfully. This builds rapport and strengthens connections.\n",
      "\n",
      "### Conclusion\n",
      "By understanding and integrating these archetypes, you can develop a more well-rounded and charismatic personality. Each archetype offers different strengths that, when combined, can enhance your social skills and personal development. Remember, the goal is not to rigidly adhere to these archetypes but to use them as guides to explore and express different aspects of your personality authentically.\n"
     ]
    }
   ],
   "source": [
    "from rizzbot_agentic import Rizzbot\n",
    "\n",
    "bot = Rizzbot()\n",
    "\n",
    "# Agentic chain route\n",
    "response = bot.answer_question(\"What makes David Dobrik popular?\")\n",
    "print(\"Chain Output:\\n\", response)\n",
    "\n",
    "response2 = bot.answer_question(\"What are the masculine archetypes, and how do these relate to charisma?\")\n",
    "print(\"Chain Output:\\n\", response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5788f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 16:56:57,307 - INFO - Initializing Rizzbot...\n",
      "2025-07-02 16:56:57,309 - INFO - Loading environment variables...\n",
      "2025-07-02 16:56:57,314 - INFO - Setting up LLM models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Rizzbot test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 16:56:58,037 - INFO - Connecting to Pinecone vector stores...\n",
      "2025-07-02 16:56:58,040 - INFO - Setting up prompt templates...\n",
      "2025-07-02 16:56:58,041 - INFO - Building agent chain...\n",
      "2025-07-02 16:56:58,041 - INFO - Building agent execution chain...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not a mapping",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Test completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mtest_rizzbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtest_rizzbot\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Rizzbot test...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Initialize bot (you'll see all the initialization logs)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m bot = \u001b[43mRizzbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Check system stats first\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m System Stats:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karel\\Ironhack-Bootcamp-Assignments\\Rizzbot\\rizzbot_agentic_v2.py:87\u001b[39m, in \u001b[36mRizzbot.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.no_answer_response = \u001b[33m\"\u001b[39m\u001b[33mSorry bro, I couldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find enough info to answer that confidently.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mBuilding agent chain...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_agent_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mRizzbot initialization complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karel\\Ironhack-Bootcamp-Assignments\\Rizzbot\\rizzbot_agentic_v2.py:185\u001b[39m, in \u001b[36mRizzbot._build_agent_chain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    177\u001b[39m     content, confidence = \u001b[38;5;28mself\u001b[39m._multi_query_search(q)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    179\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: content,\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMedium (Full-text): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstrategy\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMulti-Query Full Search\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m     }\n\u001b[32m    184\u001b[39m answer_from_summaries = (\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     {\n\u001b[32m    186\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m q: q,\n\u001b[32m    187\u001b[39m         **get_summaries_with_confidence,\n\u001b[32m    188\u001b[39m     }\n\u001b[32m    189\u001b[39m     | \u001b[38;5;28mself\u001b[39m.enhanced_prompt_template\n\u001b[32m    190\u001b[39m     | \u001b[38;5;28mself\u001b[39m.main_llm\n\u001b[32m    191\u001b[39m     | StrOutputParser()\n\u001b[32m    192\u001b[39m )\n\u001b[32m    194\u001b[39m answer_from_full = (\n\u001b[32m    195\u001b[39m     {\n\u001b[32m    196\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m q: q,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m     | StrOutputParser()\n\u001b[32m    202\u001b[39m )\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_summaries\u001b[39m(q):\n",
      "\u001b[31mTypeError\u001b[39m: 'function' object is not a mapping"
     ]
    }
   ],
   "source": [
    "from rizzbot_agentic_v2 import Rizzbot\n",
    "\n",
    "\n",
    "def test_rizzbot():\n",
    "    print(\"Starting Rizzbot test...\")\n",
    "    \n",
    "    # Initialize bot (you'll see all the initialization logs)\n",
    "    bot = Rizzbot()\n",
    "    \n",
    "    # Check system stats first\n",
    "    print(\"\\n System Stats:\")\n",
    "    stats = bot.get_stats()\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TEST 1: Game of Thrones Characters\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    response1 = bot.answer_question(\"Who are the most charismatic characters in Game of Thrones and why?\")\n",
    "    print(\"\\nChain Output:\")\n",
    "    print(response1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TEST 2: Masculine Archetypes\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    response2 = bot.answer_question(\"What are the masculine archetypes, and how do these relate to charisma?\")\n",
    "    print(\"\\n Chain Output:\")\n",
    "    print(response2)\n",
    "    \n",
    "    print(\"\\n Test completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_rizzbot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
